{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist(data, classes, incorrect=None):\n",
    "    for i in range(10):\n",
    "        idxs = (classes == i) #조건에 맞는 index만 True 나머지는 False로 리턴된다.\n",
    "        # 클래스 i에 해당하는 10개의 데이터\n",
    "        \n",
    "        if incorrect is not None:\n",
    "            idxs *= incorrect\n",
    "        \n",
    "        images = data[idxs][0:10] #True조건을 만족하는 index로 data를 뽑고 그 중 10개를 뽑는다.\n",
    "            \n",
    "        for j in range(5):   \n",
    "            plt.subplot(5, 10, i + j*10 + 1) # 행, 열, plot번호\n",
    "            plt.imshow(images[j].reshape(28, 28), cmap='gray')\n",
    "            # 클래스당 타이틀 표시\n",
    "            if j == 0:\n",
    "                plt.title(i)\n",
    "            plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./mnist-in-csv/mnist_train.csv\")\n",
    "train_input = train_data.iloc[:,1:].values\n",
    "train_input = np.reshape(train_input, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data['label']\n",
    "train_target = pd.get_dummies(train_label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./mnist-in-csv/mnist_test.csv\")\n",
    "test_input = test_data.iloc[:,1:].values\n",
    "test_input = np.reshape(test_input, [-1,28,28,1])\n",
    "test_label = test_data['label']\n",
    "test_target = pd.get_dummies(test_label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Input_Layer'):\n",
    "    input_layer = tf.placeholder(tf.float32, [None, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv_Layer1'):\n",
    "    conv1_kernel = tf.Variable(tf.random_uniform([5, 5, 1, 16], minval=-1, maxval=1),\n",
    "                              dtype=tf.float32, name=\"Conv1_Kernel\")\n",
    "    conv1_bias = tf.Variable(tf.random_uniform([16], minval=-1, maxval=1),\n",
    "                            dtype=tf.float32, name=\"Conv1_Bias\")\n",
    "    conv1_layer = tf.nn.conv2d(input_layer, conv1_kernel, \n",
    "                               strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv1_layer = tf.nn.bias_add(conv1_layer, conv1_bias)\n",
    "    conv1_relu = tf.nn.relu(conv1_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pooling_Layer1'):\n",
    "    pool1_layer = tf.nn.max_pool(conv1_relu, \n",
    "                                 [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv_Layer2'):\n",
    "    conv2_kernel = tf.Variable(tf.random_uniform([3, 3, 16, 32], minval=-1, maxval=1),\n",
    "                              dtype=tf.float32, name=\"Conv2_Kernel\")\n",
    "    conv2_bias = tf.Variable(tf.random_uniform([32], minval=-1, maxval=1),\n",
    "                            dtype=tf.float32, name=\"Conv2_Bias\")\n",
    "    conv2_layer = tf.nn.conv2d(pool1_layer, conv2_kernel, \n",
    "                               strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv2_layer = tf.nn.bias_add(conv2_layer, conv2_bias)\n",
    "    conv2_relu = tf.nn.relu(conv2_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pooling_Layer2'):\n",
    "    pool2_layer = tf.nn.max_pool(conv2_relu, \n",
    "                                 [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Hidden_Layer'):\n",
    "    pool2_layer_flat = tf.reshape(pool2_layer, [-1, 3*3*32])\n",
    "    hidden_weights = tf.Variable(tf.random_uniform([3*3*32, 100], minval=-1, maxval=1),\n",
    "                                 dtype=tf.float32, name='Hidden_Weights')\n",
    "    hidden_bias = tf.Variable(tf.random_uniform([100], minval=-1, maxval=1),\n",
    "                             dtype=tf.float32, name='Hidden_Bias')\n",
    "    hidden_layer = tf.nn.bias_add(tf.matmul(pool2_layer_flat, hidden_weights), hidden_bias)\n",
    "    hidden_relu = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Output_Layer'):\n",
    "    output_weights = tf.Variable(tf.random_uniform([100, 10], minval=-1, maxval=1),\n",
    "                                 dtype=tf.float32, name='Output_Weights')\n",
    "    output_bias = tf.Variable(tf.random_uniform([10], minval=-1, maxval=1),\n",
    "                             dtype=tf.float32, name='Output_Bias')\n",
    "    output_layer = tf.nn.bias_add(tf.matmul(hidden_relu, output_weights), output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Cost'):\n",
    "    target = tf.placeholder(tf.float32, [None, 10])\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=target, \n",
    "                                                               logits=output_layer)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.005).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Metric'):\n",
    "    accuracy = tf.metrics.accuracy(tf.argmax(target,1), tf.argmax(output_layer,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initializers.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "BATCH = 10\n",
    "BATCH_SIZE = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(EPOCH):\n",
    "    sess.run(tf.initializers.local_variables())\n",
    "\n",
    "    for batch in range(BATCH):\n",
    "        batch_input = train_input[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        batch_target = train_target[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "\n",
    "        sess.run(optimizer, feed_dict={input_layer: batch_input,\n",
    "                                       target: batch_target})\n",
    "\n",
    "    train_cost, train_acc = sess.run([cost, accuracy], feed_dict={input_layer: train_input,\n",
    "                                                                  target: train_target})\n",
    "    print(i, train_cost, train_acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = sess.run(output_layer, feed_dict={input_layer: test_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label = np.argmax(output_classes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist(test_input, output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
